{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# 1. Đọc dữ liệu từ file CSV\n",
    "def read_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    texts = df['Review'].tolist()\n",
    "    labels = [1 if sentiment == 'Tích cực' else 0 for sentiment in df['Sentiment']]\n",
    "    return texts, labels\n",
    "\n",
    "# 2. Tạo Dataset (giữ nguyên như trước)\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiengviet = pd.read_csv('/content/drive/MyDrive/Gemini_Thi_AI/Demo_TiengViet/tonghop_tiengviet_review.csv')\n",
    "df_tiengviet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Huấn luyện mô hình \n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, device, epochs=3):\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_labels_list = [], []\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels_list.extend(labels.cpu().numpy())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_accuracy = accuracy_score(train_labels_list, train_preds)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_dataloader)}, Train Accuracy: {train_accuracy}\")\n",
    "        \n",
    "        # Đánh giá trên tập validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                \n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return train_accuracies, val_accuracies, val_labels, val_preds\n",
    "\n",
    "def plot_accuracy(train_accuracies, val_accuracies):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Train vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('accuracy_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(true_labels, pred_labels):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(true_labels, pred_probs):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Đường dẫn đến file CSV\n",
    "    file_path = '/content/drive/MyDrive/Gemini_Thi_AI/Demo_TiengViet/tonghop_tiengviet_review.csv'\n",
    "    \n",
    "    # Đọc dữ liệu\n",
    "    texts, labels = read_data(file_path)\n",
    "    \n",
    "    # Chia dữ liệu thành tập train và test\n",
    "    train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Chuẩn bị mô hình và tokenizer\n",
    "    model_name = 'vinai/phobert-base'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    \n",
    "    # Chuẩn bị dataset và dataloader\n",
    "    max_length = 128\n",
    "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "    test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    train_accuracies, val_accuracies, val_labels, val_preds = train_model(model, train_dataloader, test_dataloader, device, epochs=3)\n",
    "    \n",
    "    # Vẽ biểu đồ\n",
    "    plot_accuracy(train_accuracies, val_accuracies)\n",
    "    plot_confusion_matrix(val_labels, val_preds)\n",
    "    \n",
    "    # Tính toán xác suất dự đoán cho ROC curve\n",
    "    model.eval()\n",
    "    val_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)[:, 1]  # Lấy xác suất cho lớp tích cực\n",
    "            val_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    plot_roc_curve(val_labels, val_probs)\n",
    "    \n",
    "    # Lưu mô hình\n",
    "    model.save_pretrained('/content/drive/MyDrive/Gemini_Thi_AI/Demo_TiengViet/model_tiengviet')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
